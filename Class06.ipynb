{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY+KtbYEZFLkIjsnycJ1DN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/IntelligentCommunication/blob/main/Class06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Collection and Storage Techniques**\n",
        "Integration with external data capture systems, such as third-party APIs, IoT sensors, and social media platforms, is becoming increasingly common. This allows companies to extract and process information directly within their internal systems, making it more accessible for analysis and decision-making. However, due to unpredictable formats and potential system performance impacts, security and performance considerations must be considered. Efficient data storage is crucial for systems processing large amounts of data. Factors like data type, volume, system scalability, and fast access influence storage. To achieve this, use databases that can handle large volumes without compromising performance. Mix relational and non-relational databases for different data types. Data compression reduces space without compromising integrity. Indexes in databases ensure quick queries without searching for information in every record. Data cleansing and validation are essential for data management to prevent noise, errors, and duplicate data. Cleansing involves standardizing input formats, removing duplicates, and correcting errors. Validation ensures data meets expected standards before saving to the database. This process should be performed on multiple layers to prevent users from entering incorrect data and to ensure data from external sources or APIs aligns with system requirements. Organizations are increasingly managing large volumes of big data due to the internet expansion, IoT proliferation, and digitalization. Distributed storage and processing, using technologies like Hadoop and Apache Spark, are key approaches for handling large volumes of data effectively."
      ],
      "metadata": {
        "id": "z1KyucHvgY84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ubBSP28cgTBv"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a seed for reproduITbilage:\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating data:\n",
        "n = 100\n",
        "names = ['Alice', 'Bob', 'Charlie', 'David', 'Eva']\n",
        "data = {\n",
        "    'id': range(1, n + 1),\n",
        "    'name': np.random.choice(names, n),\n",
        "    'age': np.random.randint(22, 60, n),\n",
        "    'salary': np.round(np.random.uniform(30000, 120000, n), 2),\n",
        "    'departament': np.random.choice(['Sales', 'IT', 'RH', 'Finance'], n),\n",
        "}"
      ],
      "metadata": {
        "id": "xmMS4TNJgfj6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame:\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Introducting some null and duplicated values for simulation:\n",
        "df.loc[5, 'salary'] = np.nan\n",
        "df = pd.concat([df, df.iloc[[3]]])\n",
        "\n",
        "# Displaying the simulated data:\n",
        "print('Simulated data:')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzXcznKJgi4o",
        "outputId": "7adb4ddf-620c-4dfa-da8b-73a8c8acae21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulated data:\n",
            "   id     name  age    salary departament\n",
            "0   1    David   49  58870.21       Sales\n",
            "1   2      Eva   28  46786.67       Sales\n",
            "2   3  Charlie   30  33669.76          RH\n",
            "3   4      Eva   29  83180.36          IT\n",
            "4   5      Eva   33  90980.79     Finance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data treatment and cleaning:\n",
        "# Checking null data:\n",
        "print('\\nChecking null values:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Filling null entries safely:\n",
        "df['salary'] = df['salary'].fillna(df['salary'].mean())\n",
        "\n",
        "# Removing duplicates:\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Checking the data after the treatment:\n",
        "print('\\nData after treatment:')\n",
        "print(df.info())\n",
        "\n",
        "# Simple analysis:\n",
        "avg_salary_by_departament = df.groupby('departament')['salary'].mean()\n",
        "print('\\nAverage salary by department:')\n",
        "print(avg_salary_by_departament)\n",
        "\n",
        "# Filtering data:\n",
        "employees_above_50k = df[df['salary'] > 50000]\n",
        "print('\\nEmployees with salary above 50k:')\n",
        "print(employees_above_50k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cmav6fKgqE0",
        "outputId": "306889bd-1b3a-4971-98c7-f7a9e040077c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking null values:\n",
            "id             0\n",
            "name           0\n",
            "age            0\n",
            "salary         1\n",
            "departament    0\n",
            "dtype: int64\n",
            "\n",
            "Data after treatment:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   id           100 non-null    int64  \n",
            " 1   name         100 non-null    object \n",
            " 2   age          100 non-null    int64  \n",
            " 3   salary       100 non-null    float64\n",
            " 4   departament  100 non-null    object \n",
            "dtypes: float64(1), int64(2), object(2)\n",
            "memory usage: 4.7+ KB\n",
            "None\n",
            "\n",
            "Average salary by department:\n",
            "departament\n",
            "Finance    72704.478148\n",
            "IT         83793.250714\n",
            "RH         79217.790063\n",
            "Sales      71819.087619\n",
            "Name: salary, dtype: float64\n",
            "\n",
            "Employees with salary above 50k:\n",
            "     id     name  age       salary departament\n",
            "0     1    David   49   58870.2100       Sales\n",
            "3     4      Eva   29   83180.3600          IT\n",
            "4     5      Eva   33   90980.7900     Finance\n",
            "5     6      Bob   55   77245.9415          RH\n",
            "6     7  Charlie   54   76088.3800       Sales\n",
            "..  ...      ...  ...          ...         ...\n",
            "94   95    Alice   27   85350.6500       Sales\n",
            "95   96  Charlie   43  119104.8500          IT\n",
            "97   98      Bob   37   76649.6700          RH\n",
            "98   99      Bob   54  108963.5800       Sales\n",
            "99  100    Alice   30   96669.1800     Finance\n",
            "\n",
            "[80 rows x 5 columns]\n"
          ]
        }
      ]
    }
  ]
}